# FinPattern-Engine

Ein modulares System fÃ¼r Mustererkennung in Finanzmarktdaten (Tick- und Bardaten) mit Fokus auf reproduzierbare Trading-Strategien.

## ğŸ¯ Zielsetzung

FinPattern-Engine ist ein umfassendes Backtesting- und Forschungssystem fÃ¼r Trading-Strategien, das zwei komplementÃ¤re AnsÃ¤tze zur Mustererkennung unterstÃ¼tzt:

- **Freie Mustererkennung**: Datengetriebene Entdeckung von Mustern mittels Machine Learning
- **Template-basierte Suche**: Mustererkennung basierend auf vordefiniertem Indikator-Katalog

Alle Ergebnisse sind vollstÃ¤ndig reproduzierbar und kÃ¶nnen direkt als PineScript v5 fÃ¼r TradingView exportiert werden.

## ğŸ—ï¸ Architektur

Das System basiert auf einer modularen Pipeline-Architektur mit 14 Kernmodulen:

```
DataIngest â†’ Labeling â†’ FeatureEngine â†’ Splitter â†’ [FreeSearch|DBSearch] 
    â†’ RLParamTuner â†’ Backtester â†’ Validator â†’ Exporter â†’ Reporter
```

Gesteuert wird der gesamte Ablauf durch einen zentralen **Orchestrator** (State Machine), der die Koordination zwischen den Modulen Ã¼bernimmt.

## ğŸ“‹ Module

| Modul | Status | Beschreibung |
|-------|--------|-------------|
| **DataIngest** | âœ… **VollstÃ¤ndig** | Tickdaten einlesen, normalisieren, Bars erzeugen |
| **Labeling** | ğŸ“‹ Geplant | Triple-Barrier Labels (TP/SL/Timeout) |
| **FeatureEngine** | ğŸ“‹ Geplant | Technische Indikatoren berechnen |
| **Splitter** | ğŸ“‹ Geplant | Walk-Forward, Purged/Embargo CV, Session-Splits |
| **FreeSearch** | ğŸ“‹ Geplant | Datengetriebene Musterfindung (Trees, RuleFit) |
| **DBSearch** | ğŸ“‹ Geplant | Musterkatalog + Parametertuning |
| **RLParamTuner** | ğŸ“‹ Geplant | Reinforcement Learning fÃ¼r Parametrisierung |
| **Backtester** | ğŸ“‹ Geplant | Kennzahlen pro Regel |
| **Validator** | ğŸ“‹ Geplant | OOS-Kriterien prÃ¼fen |
| **Exporter** | ğŸ“‹ Geplant | Pine v5, Markdown, CSV |
| **Reporter** | ğŸ“‹ Geplant | Charts, Reports |
| **Orchestrator** | âš ï¸ **Basis** | Ablaufsteuerung |
| **Persistence** | ğŸ“‹ Geplant | Versionierung, Resume |
| **GUI** | ğŸ“‹ Geplant | Buttons + Visualisierung |

## ğŸš€ Schnellstart

### Voraussetzungen

- Python 3.11+
- Linux-Umgebung
- Mindestens 16GB RAM (empfohlen: 32GB+)
- SSD-Speicher fÃ¼r optimale Performance

### Installation

```bash
git clone https://github.com/baumfaeller24/Linux-Superhelfer-Floki.git
cd Linux-Superhelfer-Floki
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Erste Schritte

```bash
# Demo mit Beispieldaten ausfÃ¼hren
python scripts/run_module.py --config configs/ingest_demo.yaml

# Oder mit eigenen Daten
python scripts/run_module.py --config configs/ingest.yaml

# GUI starten (geplant)
python src/gui/main.py
```

## ğŸ“Š Datenformat

### Eingabe
- **Tickdaten**: CSV mit Spalten `timestamp`, `bid`, `ask`, `[volume]`
- **Format**: ISO8601 UTC Timestamps
- **Konfiguration**: YAML fÃ¼r Run-Parameter

### Ausgabe (DataIngest)
- **Normalisierte Ticks**: `raw_norm.parquet`
- **Zeit-Bars**: `bars_1m.parquet` (OHLC + Spread-Info)
- **Tick-Bars**: `bars_100tick.parquet`, `bars_1000tick.parquet`
- **QualitÃ¤tsbericht**: `quality_report.json`
- **Manifest**: `manifest.json` mit Metadaten und Versionierung

### Erweiterte Bar-Schema

```python
BAR_COLUMNS = [
    "symbol",           # z.B. "EURUSD"
    "frame",            # z.B. "1m", "100t"
    "t_open_ns",        # Ã–ffnungszeit (Nanosekunden seit Epoch)
    "t_close_ns",       # SchlieÃŸzeit (Nanosekunden seit Epoch)
    "o", "h", "l", "c", # OHLC Preise (Mid/Bid/Ask je nach Basis)
    "o_bid", "o_ask",   # ErÃ¶ffnungs-Bid/Ask
    "c_bid", "c_ask",   # Schluss-Bid/Ask
    "spread_mean",      # Durchschnittlicher Spread
    "n_ticks",          # Anzahl Ticks in diesem Bar
    "v_sum",            # Volumen (falls verfÃ¼gbar)
    "tick_first_id",    # ID des ersten Ticks
    "tick_last_id",     # ID des letzten Ticks
    "gap_flag"          # 1 wenn DatenlÃ¼cke erkannt
]
```

## ğŸ¯ Performance-Ziele

- **Datenvolumen**: Monatsdaten EUR/USD (ca. 1-2 Mio. Ticks) in <4h
- **RAM-Nutzung**: â‰¤100 GB bei Bar-Bildung
- **Reproduzierbarkeit**: Identische Ergebnisse bei gleichem Seed
- **ModularitÃ¤t**: Jedes Modul einzeln testbar und austauschbar

## ğŸ“ Projektstruktur

```
finpattern-engine/
â”œâ”€â”€ core/                 # Neue modulare Struktur
â”‚   â”œâ”€â”€ data_ingest/      # âœ… VollstÃ¤ndig implementiert
â”‚   â”œâ”€â”€ orchestrator/     # âš ï¸ Basis-Implementation
â”‚   â””â”€â”€ [weitere Module]  # ğŸ“‹ Geplant
â”œâ”€â”€ src/                  # Legacy-Struktur (wird migriert)
â”œâ”€â”€ samples/              # âœ… Beispiel-Tickdaten
â”œâ”€â”€ scripts/              # âœ… AusfÃ¼hrungs-Scripts
â”œâ”€â”€ tests/                # Unit- und Integrationstests
â”œâ”€â”€ configs/              # YAML-Konfigurationen
â”œâ”€â”€ docs/                 # Dokumentation
â””â”€â”€ runs/                 # Output-Verzeichnis fÃ¼r LÃ¤ufe
```

## ğŸ”§ Entwicklung

### Entwicklungsumgebung

```bash
# Development Dependencies installieren
pip install -r requirements-dev.txt

# Tests ausfÃ¼hren
pytest tests/

# Code-QualitÃ¤t prÃ¼fen
black src/ core/
flake8 src/ core/
mypy src/ core/
```

### Governance & Standards

- **Determinismus**: Alle Module verwenden kontrollierte Seeds
- **Versionierung**: Semantische Versionen fÃ¼r Module und Schemas
- **Logging**: Strukturierte Logs in `progress.jsonl`
- **Fehlercodes**: Standardisierte Error-Codes fÃ¼r alle Module
- **Performance**: Parquet mit Snappy-Kompression, Chunked I/O

### Error-Codes

```python
MISSING_COLUMN = "MISSING_COLUMN"      # Erforderliche Spalte fehlt
NEGATIVE_SPREAD = "NEGATIVE_SPREAD"    # Ask < Bid erkannt
UNSORTED_INPUT = "UNSORTED_INPUT"      # Daten nicht zeitlich sortiert
TIMEZONE_ERROR = "TIMEZONE_ERROR"      # Zeitzone-Parsing fehlgeschlagen
IO_ERROR = "IO_ERROR"                  # Datei-I/O Fehler
GAP_EXCESS = "GAP_EXCESS"              # Zu groÃŸe DatenlÃ¼cken
CONFIG_ERROR = "CONFIG_ERROR"          # Konfigurationsfehler
```

## ğŸ§ª Testing

Das DataIngest-Modul ist vollstÃ¤ndig getestet:

```bash
# Spezifische Tests fÃ¼r DataIngest
pytest tests/test_data_ingest.py -v

# Mit Demo-Daten testen
python scripts/run_module.py --config configs/ingest_demo.yaml
```

## ğŸ¤ Beitragen

1. Fork des Repositories
2. Feature-Branch erstellen (`git checkout -b feature/amazing-feature`)
3. Ã„nderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request erstellen

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT-Lizenz. Siehe [LICENSE](LICENSE) fÃ¼r Details.

## ğŸ¤ Support

Bei Fragen oder Problemen:
- GitHub Issues fÃ¼r Bug-Reports und Feature-Requests
- Dokumentation unter `docs/`
- Beispiel-Konfigurationen unter `configs/`

---

**Entwickelt fÃ¼r professionelle Trading-Strategieentwicklung mit Fokus auf Reproduzierbarkeit und wissenschaftliche RigorositÃ¤t.**
