# üß™ Test-Guide: Modul 1 (DataIngest)

## √úbersicht

Das DataIngest-Modul ist vollst√§ndig testbar und bietet verschiedene Test-Szenarien f√ºr unterschiedliche Anwendungsf√§lle.

## üöÄ 1. Schnelltest (Demo-Modus)

### Einfachster Test mit integrierten Beispieldaten

```bash
cd /home/ubuntu/Linux-Superhelfer-Floki
python test_data_ingest.py
```

**Was passiert:**
- Verwendet integrierte `eurusd_sample.csv` (6 Ticks)
- Generiert alle 3 Bar-Typen (1m, 100t, 1000t)
- Zeigt Qualit√§tsbericht und Manifest
- Dauert < 1 Sekunde

**Erwartete Ausgabe:**
```
üöÄ Testing DataIngest module with demo data...
‚úÖ DataIngest completed successfully!
üìä Symbol: EURUSD
üìÅ Generated frames: 3
   - 1m: runs/test_demo/bars_1m.parquet
   - 100t: runs/test_demo/bars_100tick.parquet
   - 1000t: runs/test_demo/bars_1000tick.parquet
üìà Processed ticks: 6
üìä Gap coverage: 100.0%
üîñ Module version: 1.1
üîñ Schema version: 1.0
```

---

## üìä 2. Realistische Tests mit verschiedenen Datengr√∂√üen

### 2.1 Kleine Datenmenge (1K Ticks)

```bash
# Konfiguration f√ºr kleine Daten
cat > configs/test_small.yaml << EOF
symbol: EURUSD
out_dir: ./runs/test_small
csv:
  path: ./samples/ticks/eurusd_small.csv
bar_frames:
- type: time
  unit: 1m
- type: tick
  count: 100
demo: false
EOF

# Test ausf√ºhren
python -c "
import yaml
from core.data_ingest.data_ingest import run
config = yaml.safe_load(open('configs/test_small.yaml'))
result = run(config)
print(f'‚úÖ Erfolgreich! Frames: {len(result[\"frames\"])}')
"
```

### 2.2 Mittlere Datenmenge (10K Ticks)

```bash
# Bereits vorkonfiguriert
python -c "
import yaml, json
from core.data_ingest.data_ingest import run
config = yaml.safe_load(open('configs/test_medium.yaml'))
result = run(config)

# Ergebnisse anzeigen
for frame_name, frame_path in result['frames'].items():
    import pandas as pd
    df = pd.read_parquet(frame_path)
    print(f'{frame_name}: {len(df)} Bars')

# Qualit√§tsbericht
with open(result['quality_report']) as f:
    quality = json.load(f)
print(f'Verarbeitete Ticks: {quality[\"n_raw_rows\"]:,}')
print(f'Gap-Abdeckung: {quality[\"gap_coverage_percent\"]:.1f}%')
"
```

**Erwartete Ausgabe:**
```
1m: 82 Bars
100t: 100 Bars  
1000t: 10 Bars
Verarbeitete Ticks: 10,000
Gap-Abdeckung: 100.0%
```

### 2.3 Gro√üe Datenmenge (100K Ticks)

```bash
# Konfiguration f√ºr gro√üe Daten
cat > configs/test_large.yaml << EOF
symbol: EURUSD
out_dir: ./runs/test_large
csv:
  path: ./samples/ticks/eurusd_large.csv
bar_frames:
- type: time
  unit: 1m
- type: tick
  count: 1000
max_missing_gap_seconds: 60
trim_weekend: true
demo: false
EOF

# Performance-Test
time python -c "
import yaml
from core.data_ingest.data_ingest import run
config = yaml.safe_load(open('configs/test_large.yaml'))
result = run(config)
print(f'‚úÖ 100K Ticks verarbeitet!')
"
```

---

## üß™ 3. Unit-Tests (pytest)

### 3.1 Alle Tests ausf√ºhren

```bash
# Vollst√§ndige Test-Suite
python -m pytest tests/test_core_data_ingest.py -v

# Spezifische Tests
python -m pytest tests/test_core_data_ingest.py::TestCoreDataIngest::test_demo_mode -v
python -m pytest tests/test_core_data_ingest.py::TestCoreDataIngest::test_full_pipeline_with_time_bars -v
python -m pytest tests/test_core_data_ingest.py::TestCoreDataIngest::test_tick_bars_generation -v
```

### 3.2 Error-Handling Tests

```bash
# Test f√ºr fehlende Spalten
python -m pytest tests/test_core_data_ingest.py::TestCoreDataIngest::test_error_handling_missing_columns -v

# Test f√ºr negative Spreads
python -m pytest tests/test_core_data_ingest.py::TestCoreDataIngest::test_error_handling_negative_spread -v
```

### 3.3 Verf√ºgbare Test-Kategorien

| Test | Beschreibung | Dauer |
|------|-------------|-------|
| `test_demo_mode` | Demo-Modus mit Beispieldaten | ~0.5s |
| `test_full_pipeline_with_time_bars` | Komplette Pipeline mit Zeit-Bars | ~1s |
| `test_tick_bars_generation` | Tick-Bar Generierung | ~1s |
| `test_price_basis_options` | Verschiedene Preis-Basen (mid/bid/ask) | ~2s |
| `test_gap_analysis` | Gap-Erkennung mit Testl√ºcken | ~1s |
| `test_weekend_trimming` | Wochenend-Daten entfernen | ~1s |
| `test_progress_logging` | Progress-Log Validierung | ~1s |
| `test_error_handling_*` | Verschiedene Error-Szenarien | ~0.5s |

---

## üñ•Ô∏è 4. GUI-Tests (Streamlit)

### 4.1 GUI starten

```bash
# Hauptinterface
streamlit run src/gui/main.py

# Direkt DataIngest-Modul
streamlit run src/gui/data_ingest_gui.py
```

### 4.2 GUI-Test-Szenarien

#### Szenario A: Demo-Modus
1. ‚úÖ Demo-Modus aktivieren
2. ‚úÖ Symbol: EURUSD
3. ‚úÖ Alle Bar-Typen ausw√§hlen
4. ‚úÖ "DataIngest ausf√ºhren" klicken
5. ‚úÖ Progress-Bar beobachten
6. ‚úÖ Ergebnisse downloaden

#### Szenario B: CSV-Upload
1. ‚úÖ Demo-Modus deaktivieren
2. ‚úÖ CSV-Datei hochladen (`samples/ticks/eurusd_medium.csv`)
3. ‚úÖ Parameter anpassen (Gap-Schwelle, Preis-Basis)
4. ‚úÖ Ausf√ºhren und Ergebnisse pr√ºfen

#### Szenario C: Erweiterte Einstellungen
1. ‚úÖ "Erweiterte Einstellungen" √∂ffnen
2. ‚úÖ Max. Gap auf 30 Sekunden setzen
3. ‚úÖ Wochenenden-Trimming deaktivieren
4. ‚úÖ Unterschiede in Qualit√§tsbericht beobachten

---

## üìã 5. Manuelle Validierung

### 5.1 Ausgabe-Dateien pr√ºfen

```bash
# Nach einem Test die generierten Dateien untersuchen
ls -la runs/test_medium/

# Manifest pr√ºfen
cat runs/test_medium/manifest.json | jq '.'

# Qualit√§tsbericht pr√ºfen  
cat runs/test_medium/quality_report.json | jq '.'

# Progress-Log pr√ºfen
tail -5 runs/test_medium/progress.jsonl
```

### 5.2 Bar-Daten analysieren

```bash
# 1-Minuten Bars untersuchen
python -c "
import pandas as pd
df = pd.read_parquet('runs/test_medium/bars_1m.parquet')
print(f'Bars: {len(df)}')
print(f'Zeitspanne: {df.index[0]} bis {df.index[-1]}')
print(f'OHLC-Konsistenz: {(df[\"h\"] >= df[\"l\"]).all()}')
print(f'Durchschnittliche Ticks pro Bar: {df[\"n_ticks\"].mean():.1f}')
"

# 100-Tick Bars untersuchen
python -c "
import pandas as pd
df = pd.read_parquet('runs/test_medium/bars_100tick.parquet')
print(f'Tick-Bars: {len(df)}')
print(f'Alle haben 100 Ticks: {(df[\"n_ticks\"] == 100).all()}')
print(f'Frame-Typ korrekt: {(df[\"frame\"] == \"100t\").all()}')
"
```

### 5.3 Schema-Validierung

```bash
# Pr√ºfe ob alle 18 Spalten vorhanden sind
python -c "
import pandas as pd
from core.data_ingest.schema import BAR_COLUMNS

df = pd.read_parquet('runs/test_medium/bars_1m.parquet')
expected = set(BAR_COLUMNS)
actual = set(df.columns)

print(f'Erwartete Spalten: {len(expected)}')
print(f'Tats√§chliche Spalten: {len(actual)}')
print(f'Schema korrekt: {expected == actual}')

if expected != actual:
    print(f'Fehlende: {expected - actual}')
    print(f'Zus√§tzliche: {actual - expected}')
"
```

---

## ‚ö° 6. Performance-Tests

### 6.1 Geschwindigkeits-Benchmark

```bash
# Zeitmessung f√ºr verschiedene Datengr√∂√üen
echo "=== Performance-Test ==="

echo "1K Ticks:"
time python -c "
from core.data_ingest.data_ingest import run
config = {'out_dir': './runs/perf_1k', 'demo': True, 'bar_frames': [{'type': 'time', 'unit': '1m'}]}
run(config)
"

echo "10K Ticks:"  
time python -c "
import yaml
from core.data_ingest.data_ingest import run
config = yaml.safe_load(open('configs/test_medium.yaml'))
config['out_dir'] = './runs/perf_10k'
run(config)
"
```

### 6.2 Memory-Profiling

```bash
# Memory-Verbrauch messen (falls memory_profiler installiert)
pip install memory-profiler

python -m memory_profiler -c "
from core.data_ingest.data_ingest import run
import yaml
config = yaml.safe_load(open('configs/test_medium.yaml'))
config['out_dir'] = './runs/memory_test'
run(config)
"
```

---

## üîç 7. Debugging und Troubleshooting

### 7.1 Verbose Logging

```bash
# Progress-Log in Echtzeit verfolgen
python -c "
import yaml
from core.data_ingest.data_ingest import run
config = yaml.safe_load(open('configs/test_medium.yaml'))
config['out_dir'] = './runs/debug_test'
run(config)
" &

# In anderem Terminal:
tail -f runs/debug_test/progress.jsonl
```

### 7.2 H√§ufige Probleme

| Problem | L√∂sung |
|---------|--------|
| `KeyError: 'csv'` | Demo-Modus aktivieren oder CSV-Pfad konfigurieren |
| `FileNotFoundError` | Pfad zu CSV-Datei pr√ºfen |
| `NEGATIVE_SPREAD` | Datenqualit√§t pr√ºfen (Ask < Bid) |
| `MISSING_COLUMN` | CSV-Format validieren (timestamp, bid, ask) |
| Pandas FutureWarnings | Normal, funktioniert trotzdem |

### 7.3 Test-Daten erstellen

```bash
# Neue Testdaten generieren
python create_test_data.py

# Eigene CSV-Datei validieren
python -c "
import pandas as pd
df = pd.read_csv('path/to/your/data.csv')
print(f'Spalten: {list(df.columns)}')
print(f'Zeilen: {len(df)}')
print(f'Erste 3 Zeilen:')
print(df.head(3))
"
```

---

## ‚úÖ 8. Test-Checkliste

Vor der Freigabe f√ºr Modul 2 sollten alle Tests erfolgreich sein:

- [ ] **Demo-Modus Test** erfolgreich
- [ ] **10K Ticks Test** erfolgreich  
- [ ] **Unit-Tests** alle bestanden
- [ ] **GUI-Test** funktional
- [ ] **Schema-Validierung** korrekt
- [ ] **Error-Handling** funktioniert
- [ ] **Performance** akzeptabel (<5s f√ºr 10K Ticks)
- [ ] **Manifest** wird korrekt erstellt
- [ ] **Progress-Logging** funktioniert
- [ ] **Alle 3 Bar-Typen** werden generiert

**Status: ‚úÖ Alle Tests bestanden - Modul 1 ist production-ready!**
